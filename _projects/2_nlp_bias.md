---
layout: page
title: Bias Toward Languages Studied in NLP Peer Reviews
description: First large-scale study quantifying language-related bias in NLP peer reviews, focusing on systematic disadvantages for non-English research.
importance: 2
category: work
related_publications: false
---

**Jul 2025 – Present** | Koç University (Repository Private)

*   First large-scale study quantifying language-related bias in NLP peer reviews, focusing on systematic disadvantages for non-English research.
*   Compiled and analyzed 6,000+ reviews from EMNLP 2023, ICLR 2025, and ICML 2025, annotated for language bias.
*   Proposed a taxonomy of five bias categories and validated LLM-based detection pipelines (GPT-5, Gemini 2.5) against human annotations (89% accuracy).
*   Findings: 12–15% of papers contained at least one biased review; English-as-Default and Contribution Erasure were the most frequent categories.
*   Contribution: Provides empirical evidence to inform fairer peer review guidelines in the NLP community.
